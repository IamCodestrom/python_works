{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales=pd.read_csv(r'D:\\GdriveBackup\\0.Projects\\Mock Projects\\DE\\Python\\Sales.csv',low_memory=False)\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=sales.groupby(['Product Category','PlainStudded','Parent Product Category','Product','Sub Product']).sum()\n",
    "a['Gross Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Product'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Sales Date']=sales['Sales Date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['new col']=sales['City']+'2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.dropna(subset=['City','State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Parent Product Category'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.drop(index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1,32,34,56,43,56]\n",
    "a\n",
    "b=np.array(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=b.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_vk(a):\n",
    "    return\\\n",
    "'V Kolhi' in a\n",
    "\n",
    "find_vk(['V Kolhi','R Sharma','MS Dhoni'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[['Gross Amount','Parent Product Category']].groupby('Parent Product Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=sales[['Product Category','PlainStudded','Gross Amount']].groupby(['Product Category','PlainStudded']).mean()\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=sales[sales['Product Category']=='Diamond Jewelry'][['Sales Date','Gross Amount']]\\\n",
    "    .groupby('Sales Date').mean()\n",
    "a.sort_index(ascending=False).plot(kind='area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by 'Product Category' and summing 'Gross Amount'\n",
    "grouped_sales = sales.groupby('Product Category')['Gross Amount'].sum()\n",
    "\n",
    "# Now printing the result\n",
    "print(grouped_sales)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[sales['Type']=='Return'].select_dtypes(include='number').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[sales['Type']=='Return'].select_dtypes(include='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[sales['Type']=='Return'][['Cost Price','Sales Price','Stone Value','Diamond Value','Gold Value','Palladium Value','Diamond Weight'\\\n",
    "                               ,'Diamond Pieces','Stone Weight','Stone Pieces','Net Weight','URD Discount Amount','OGADJUSTEDAMOUNT'\\\n",
    "                                ,'URDADDLDEDUCITON','Platinum Value', 'Hallmarking Value',\\\n",
    "                                'Handling Value', 'Silver Value', 'Setting Value', 'Labour Value',\\\n",
    "                                'Wastage Amount', 'Second Wastage Amount', 'Other Charges',\\\n",
    "                                'IGI Amount', 'PGI Amount']]*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=(sales[sales['Type']=='Return'][['Cost Price','Sales Price','Stone Value','Diamond Value','Gold Value','Palladium Value','Diamond Weight'\\\n",
    "                               ,'Diamond Pieces','Stone Weight','Stone Pieces','Net Weight','URD Discount Amount','OGADJUSTEDAMOUNT'\\\n",
    "                                ,'URDADDLDEDUCITON','Platinum Value', 'Hallmarking Value',\\\n",
    "                                'Handling Value', 'Silver Value', 'Setting Value', 'Labour Value',\\\n",
    "                                'Wastage Amount', 'Second Wastage Amount', 'PGI Amount']]<0).any()\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=(sales[sales['Type']=='Return'].select_dtypes(include='number')<0).any()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.select_dtypes(include='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Sales Date']=sales['Sales Date'].astype('date64[pyarrow]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[sales['Sales Person Name'].fillna('Na').str.contains('Mahendra')][['Sales Person Name','Gross Amount']].groupby('Sales Person Name').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=sales.set_index('Sales Date').copy()\n",
    "s.index.rename('Date',inplace=1)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.rename_axis('Sales Date',inplace=True)\n",
    "s.reset_index(inplace=True)\n",
    "s.rename_axis(None,inplace=True)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[s.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.filter([2800,28001],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test={\n",
    "    'col1':'Visaal',\n",
    "    'col2':'Peter',\n",
    "    'col3':'Harry'\n",
    "}\n",
    "for x in test.values():\n",
    "    print(x+' hai bkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2=['visaal','peter','harry']\n",
    "for x in test2:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.sort_index(axis=0,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('test_space').getOrCreate()\n",
    "\n",
    "pydf=spark.createDataFrame(s)\n",
    "pydf.show(truncate=False)\n",
    "pydf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "pydf_w_nulls=pydf.select(nanvl(col('Sub Brand'),lit(None)).alias('Sub Brand'))\n",
    "\n",
    "pydf_filled=pydf_w_nulls.na.fill({'Sub Brand':'uksb'}).distinct()\n",
    "pydf_filled.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pydf.select(col('Parent Product Category')).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "pydf.filter(col('Parent Product Category').isNull())# Filter for null values in 'Parent Product Category'\n",
    "null_rows = pydf.filter(col(\"`Parent Product Category`\")=='NaN')\n",
    "\n",
    "# Show the rows with null values\n",
    "null_rows.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=s[(s['City']=='Delhi')|(s['City']=='Thane')][['Discount','City','Gross Amount']].groupby('City')\\\n",
    "    .agg(Total_Disc=('Discount','sum'),\\\n",
    "         Avg_gross=('Gross Amount','mean'))\n",
    "x\n",
    "# x.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u=s[['Discount','City']].groupby('City').sum()\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for City == 'Delhi'\n",
    "filtered_df = pydf.filter((col('City') == 'Delhi')|( col('City')=='Thane'))\n",
    "\n",
    "# Select and alias the City column\n",
    "result_df = filtered_df.select(col('City').alias('City'), 'Customer ID', 'Discount','Gross Amount')\n",
    "\n",
    "grouped_df=result_df.groupBy('City').agg(sum('Discount').alias('TotalDisc'),\n",
    "                                         avg('Gross Amount').alias('TotalGA'))\n",
    "# Show the result\n",
    "grouped_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement=pd.read_excel(r'D:\\GdriveBackup\\0.Projects\\Mock Projects\\DE\\Python\\statement0310-1010.xlsx',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement[statement['VendorName'].fillna('ukpat').str.contains('ZOMATO')][['VendorName','Debit']]\\\n",
    ".groupby('VendorName').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement['Tran Date']=statement['Tran Date'].astype('datetime64[ms]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf=pd.to_datetime(['2024-10-06','2024-10-07'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement[statement['Tran Date'].isin(dtf)].sort_values('VendorName')[['VendorName','Debit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement['Credit']=statement['Credit'].replace('-',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement['Credit']=statement['Credit'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(statement['Debit'].agg({'total':'sum','avg':'mean'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement['Debit'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stm=spark.createDataFrame(statement)\n",
    "stm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uy=stm.filter(to_date(col('Tran Date')).isin('2024-10-06','2024-10-07'))\n",
    "uy.orderBy('VendorName').select('VendorName',col('Debit').alias('loude lage')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qw=stm.filter(col('Particulars').contains('ZOMATO'))\n",
    "qw.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stm=stm.withColumn('VendorNamewPys',split(col('Particulars'),'/').getItem(3))\n",
    "stm.limit(4).orderBy(col('Balance').desc()).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statement['Particulars'].str.split('/').str[4]\n",
    "oro=stm.select(col('Tran Date').cast('date').alias('cast_to_date'))\\\n",
    "    .distinct().orderBy(col('cast_to_date').desc())\n",
    "oro.show()\n",
    "sel_dates=['2024-10-08','2024-10-05']\n",
    "\n",
    "oro.filter(col('cast_to_date').isin(sel_dates)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oro.select(col('cast_to_date').isNotNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement.sort_values(['Tran Date','VendorName'],ascending=[True,False]).fillna({'VendorName':\\\n",
    "                                                                                 'NaVendor'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stm.orderBy('Tran Date',col('VendorName').desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stm=stm.withColumnRenamed('Init. Br','Initial Balance')\n",
    "stm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stm.select(\n",
    "    col('VendorName').alias('VendorNamewpd'),  # Alias the 'VendorName' column\n",
    "    *[col(c) for c in stm.columns if c != 'VendorName']  # Select all other columns as they are\n",
    ").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
